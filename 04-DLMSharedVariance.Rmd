# Forward Filtering Backward Sampling - Shared Variance

This chapter discusses the Dynamic Linear Model with a scale factor for the variance shared across time and its derivations at each step. The approach taken in this chapter is borrowed from West and Harrison (1997), with some details derived from Petris et al (2009). The solution we take to estimate the parameters of this model is utilized via Forward Filtering Backward Sampling (FFBS).

For full generality and to maintain a multivariate normal system in both the data and parameter matrices, we assume all $Y_{t} \in \mathbb{R}^{n_{t}}$, $\beta_{t} \in \mathbb{R}^{p}$, and $t \in \{1,\ldots,T\}$ for some integer $T$. Notice that we choose $n_{t}$ to vary with time, because the number of observations at each time point may vary depending on how much of the data is missing.


## Background

The model we are concerned with studying is a class of time-varying models called the Dynamic Linear Model. The setup for the equation follows:

\begin{equation*}
\begin{split}
Y_{t}\vert\beta_{t}, \sigma^{2} &\sim N(F_{t}\beta_{t}, \sigma^{2}V_{t})\\
\beta_{t}\vert \beta_{t-1},\sigma^{2} &\sim N(G_{t}\beta_{t-1}, \sigma^{2}W_{t})\\
\sigma^{-2} &\sim \Gamma(a_{t-1},b_{t-1})\\
\beta_{t-1}\vert \sigma^{2} &\sim N(m_{t-1}, \sigma^{2}C_{t-1})\\
\end{split}
(\#eq:dlmsetup)
\end{equation*}

Alternatively, using Normal-Inverse Gamma notation, where, if $\sigma^{-2} \sim \Gamma(a_{t-1},b_{t-1})$, $\sigma^{2} \sim IG(a_{t-1},b_{t-1})$, where $IG$ denotes an inverse Gamma distribution, we may write the above set of equations as the following:
\begin{equation*}
\begin{split}
Y_{t},\sigma^{2}\vert \beta_{t} &\sim NIG(F_{t}\beta_{t}, V_{t}, a_{t-1}, b_{t-1})\\
\beta_{t},\sigma^{2}\vert \beta_{t-1} &\sim NIG(G_{t}\beta_{t-1}, W_{t}, a_{t-1}, b_{t-1})\\
\beta_{t-1},\sigma^{2} &\sim NIG(m_{t-1}, C_{t-1}, a_{t-1}, b_{t-1})
\end{split}
(\#eq:dlmsetupnig)
\end{equation*}

The task is to acquire estimates for $\beta_{0,\ldots,T}$ and $\sigma^{2}$. This task may be divided into the forward filtering (FF) and backwards sampling (BS) steps (collectively referred to as the Forward Filter-Backwards Sampling (FFBS) algorithm): The forward filter to acquire sequential estimates of parameters and key values for the backwards sampling step to retroactively "smooth" these estimates in reverse time order. We are given a set of observations $Y_{t,j}$, and known parameters $F_{t}$, $G_{t}$, $V_{t}$, $W_{t}$, and $n_{t}$. (Frankenburg and Banerjee also apply FFBS to cases where $F_{t}$ and $G_{t}$ are not pre-specified.)

<center>
![**Figure 3.1**: The dependency graph of the DLM. The grey arrows to the data $Y_1$ to $Y_T$ are colored to emphasize the relations of the parameters other than $\phi$ to each other, not to suggest differences in the nature of their dependency.](dlm_sharedvar_graph.png){#id .class width=60% height=60%}
</center>

### A Preliminary Note

The following equations cover the forward filtering step for the set of equations for time $t$ given the parameters for the distributions at time $t-1$. Hence the equation's setup is Markovian, i.e. the state of this set of equations only depends on that of the preceding time point. Nevertheless, applications where forward filtering propagates from an initial time point $t=0$ constitute the majority of cases, and we frequently deal with cases where all the data from time $t = 0$ (no data) to $t = T$ are accounted for.

Specifically, letting $D_{t} = \{Y_{\tau}\}_{\tau=1,\ldots,t}$, we may write the set of equations in our setup as:

\begin{equation*}
\begin{split}
Y_{t},\sigma^{2}\vert \beta_{t},D_{t-1} &\sim NIG(F_{t}\beta_{t}, V_{t}, a_{t-1}, b_{t-1})\\
\beta_{t},\sigma^{2}\vert \beta_{t-1},D_{t-1} &\sim NIG(G_{t}\beta_{t-1}, W_{t}, a_{t-1}, b_{t-1})\\
\beta_{t-1},\sigma^{2}\vert D_{t-1} &\sim NIG(m_{t-1}, C_{t-1}, a_{t-1}, b_{t-1})
\end{split}
(\#eq:setupudfulldata)
\end{equation*}

We aim to derive the sequential posteriors $\beta_{t}\vert D_{t}$ and $\sigma^{2} \vert D_{t}$ respectively.

## Derivation of the Forward Filter

We proceed for some arbitrary $t$:

\begin{equation*}
\begin{split}
\beta_{t}\vert D_{t-1} &= G_{t}\beta_{t-1} + \omega_{t}, \omega_{t} \sim N(0, \sigma^{2}W_{t})\\
\beta_{t}\vert \sigma^{2}, D_{t-1} &\sim N(G_{t}m_{t-1}, \sigma^{2}(G_{t}C_{t-1}G_{t}^{\T} + W_{t}))\\
\end{split}
(\#eq:Gsetup)
\end{equation*}

Now, let $m^{*}_{t} = G_{t}m_{t-1}$ and $R_{t} = G_{t}C_{t-1}G_{t}^{\T} + W_{t}$. We then have:

\begin{equation*}
\begin{split}
Y_{t}\vert D_{t-1} &= F_{t}\beta_{t} + \nu_{t}, \nu_{t}\sim N(0, \sigma^{2}V_{t})\\
Y_{t}\vert \sigma^{2}, D_{t-1} &\sim N(F_{t}m^{*}_{t}, \sigma^{2}(F_{t}R_{t}F_{t}^{\T} + V_{t}))
\end{split}
(\#eq:Fsetup)
\end{equation*}

Since $\sigma^{2} \sim IG(a_{t-1},b_{t-1})$, we marginalize it out of $Y_{t}\vert \sigma^{2}$ to get

\begin{equation*}
Y_{t}\vert D_{t-1} \sim T_{2a_{t-1}}(F_{t}m^{*}_{t}, \frac{b_{t-1}}{a_{t-1}}(F_{t}R_{t}F_{t}^{\T} + V_{t}))
(\#eq:Ymargin)
\end{equation*}

We now have the apparatus needed to compute the sequential posterior $\beta_{t}\vert Y_{t}$ and $\sigma^{2}\vert Y_{t}$:

### Deriving $\beta_{t} \vert D_{t}$

\begin{equation*}
\begin{split}
p(\beta_{t} \vert \sigma^{2}, D_{t}) &\propto p(\beta_{t}, Y_{t}\vert \sigma^{2}, D_{t-1})\\
 &\propto p(Y_{t}\vert \beta_{t},\sigma^{2}\vert D_{t-1})p(\beta_{t}\vert \sigma^{2},  D_{t-1})\\
 &\propto \sigma^{-n_{t}}\exp\left(-\frac{1}{2\sigma^{2}}(y_{t} - F_{t}\beta_{t})^{\T}V_{t}^{-1}(y_{t} - F_{t}\beta_{t})\right)\\
 &\sigma^{-p}\exp\left(-\frac{1}{2\sigma^{2}}(\beta_{t} - m^{*}_{t})^{\T}R_{t}^{-1}(\beta_{t} - m^{*}_{t})\right)\\
 &\propto \sigma^{-(n_{t}+p)}\exp\bigl(-\frac{1}{2\sigma^{2}}[(y_{t} - F_{t}\beta_{t})^{\T}V_{t}^{-1}(y_{t} - F_{t}\beta_{t})\\
 &+ (\beta_{t} - m^{*}_{t})^{\T}R_{t}^{-1}(\beta_{t} - m^{*}_{t})]\bigr)\\
\end{split}
 (\#eq:betaud1)
\end{equation*}

Note next that
\begin{equation*}
\begin{split}
\begin{bmatrix}Y_{t}\\ \beta_{t}\end{bmatrix}\vert \sigma^{2},D_{t-1} &\sim N\left(\begin{bmatrix}F_{t}m^{*}_{t}\\ m^{*}_{t}\end{bmatrix},\sigma^{2}\begin{bmatrix}F_{t}R_{t}F_{t}^{\T} + V_{t} & F_{t}R_{t}\\
R_{t}F_{t}^{\T} & R_{t}\end{bmatrix}\right)
\end{split}
(\#eq:blocksetup)
\end{equation*}

with the cross-terms $\mathrm{Cov}(Y_{t},\beta_{t}\vert D_{t-1}) = \mathrm{Cov}(F_{t}\beta_{t} + \nu_{t},\beta_{t}\vert D_{t-1}) = F_{t}\mathrm{Cov}(\beta_{t}, \beta_{t}\vert D_{t-1}) = F_{t}R_{t}$.

Since, for the following block-normal system

\begin{equation*}
\begin{split}
\begin{bmatrix}x_{1}\\ x_{2}\end{bmatrix} &\sim N\left(\begin{bmatrix}\mu_{1}\\ \mu_{2}\end{bmatrix}, \begin{bmatrix}\Sigma_{11} & \Sigma_{12}\\
\Sigma_{21} & \Sigma_{22}\end{bmatrix}\right)
\end{split}
(\#eq:blockmateq)
\end{equation*}

we have

\begin{equation*}
x_{2}\vert x_{1} \sim N(\mu_{2} + \Sigma_{21}\Sigma_{11}^{-1}(x_{1} - \mu_{1}), \Sigma_{22} - \Sigma_{21}\Sigma_{11}^{-1}\Sigma_{12})
(\#eq:blockcondeq)
\end{equation*}

(The derivation of \@ref(eq:blockcondeq) can be found in the Appendix.)

We arrive at,

\begin{equation*}
\begin{split}
\beta_{t}\vert \sigma^{2},D_{t} &\sim N(m_{t}^{*} + R_{t}F_{t}^{\T}(F_{t}R_{t}F_{t}^{\T} + V_{t})^{-1}(Y_{t} - F_{t}m_{t}^{*}),\\
 &R_{t} - R_{t}F_{t}^{\T}(F_{t}R_{t}F_{t}^{\T} + V_{t})^{-1}F_{t}R_{t})\\
 &\sim N(m_{t}^{*} + R_{t}F_{t}^{\T}Q_{t}^{-1}(Y_{t} - F_{t}m_{t}^{*}), R_{t} - R_{t}F_{t}^{\T}Q_{t}^{-1}F_{t}R_{t})
\end{split}
(\#eq:betaud2)
\end{equation*}

where $Q_{t} = F_{t}R_{t}F_{t}^{\T} + V_{t}$.

(Note that Petris's expression for the variance suffers from a typo; to see this, simply take their $\widetilde{C}_{t}^{\T}$.)

### Deriving $\sigma^{2} \vert D_{t}$

We next deduce the density of $\sigma^{2}\vert Y_{t}$. Note before we begin that since $Y_{t}\vert D_{t-1} \sim T_{2a_{t-1}}(F_{t}m^{*}_{t}, Q_{t}) = \int NIG_{Y_{t}}(F_{t}m^{*}_{t}, Q_{t}, a_{t-1}, b_{t-1})d\sigma^{2}$, we can write $Y_{t}\vert \sigma^{2}, D_{t-1} \sim N(F_{t}m^{*}_{t}, \sigma^{2}Q_{t})$. Hence:

\begin{equation*}
\begin{split}
p(\sigma^{2}\vert D_{t}) &\propto p(Y_{t}\vert \sigma^{2}, D_{t-1})p(\sigma^{2}\vert D_{t-1})\\
 &\propto \sigma^{-n_{t}}\exp(-\frac{1}{2\sigma^{2}}(y_{t} - F_{t}m^{*}_{t})^{\T}Q_{t}^{-1}(y_{t} - F_{t}m^{*}_{t}))\sigma^{-2(a_{t-1} + 1)}\exp(-b_{t-1}\sigma^{-2})\\
 &\propto \sigma^{-2(a_{t-1} + \frac{n_{t}}{2} + 1)}\exp(-\sigma^{-2}[\frac{1}{2}(y_{t} - F_{t}m^{*}_{t})^{\T}Q_{t}^{-1}(y_{t} - F_{t}m^{*}_{t}) + b_{t-1}])
\end{split}
(\#eq:sigmaud)
\end{equation*}

We conclude that $\sigma^{-2}\vert D_{t} \sim \Gamma(a_{t},b_{t})$, where $a_{t} = a_{t-1} + \frac{n_{t}}{2}$ and $b_{t} = b_{t-1} + \frac{1}{2}(y_{t} - F_{t}m^{*}_{t})^{\T}Q_{t}^{-1}(y_{t} - F_{t}m^{*}_{t})$. Note in particular that we may write these recurrent equations in terms of $a_{0}$, $b_{0}$, so that:
\begin{equation*}
\begin{split}
a_{t} &= a_{0} + \frac{n_{t}t}{2}\\
b_{t} &= b_{0} + \frac{1}{2}\sum_{s=1}^{t}(y_{s} - F_{s}m^{*}_{s})^{\T}Q_{s}^{-1}(y_{s} - F_{s}m^{*}_{s})
\end{split}
(\#eq:sigmaparams)
\end{equation*}

This gives us the set of updating equations according to Petris Proposition 4.1.


## Derivation of the Backwards Sampling

Now that we have the parameters $\{\beta_{t},\sigma^{2}\vert D_{t}\}_{t=1,\ldots,T}$, we would like to work backwards and derive $\{\beta_{t},\sigma^{2}\vert \beta_{t+1}, D_{T}\}_{t=1,\ldots,T-1}$ to smooth our initial variable estimates:

\begin{equation*}
\begin{split}
p(\beta_{t}\vert \beta_{(t+1):T},\sigma^{2},D_{T}) &= p(\beta_{t}\vert \beta_{t+1},\sigma^{2},D_{t})\\
&= p(\beta_{t}\vert \beta_{t+1},\sigma^{2},D_{t})\\
 &= \frac{p(\beta_{t+1}\vert \beta_{t},D_{t})p(\beta_{t}\vert D_{t})}{p(\beta_{t+1}\vert D_{t})}\\
 &\propto p(\beta_{t+1}\vert \beta_{t},D_{t})p(\beta_{t}\vert D_{t})\\
 &\propto \exp\left(-\frac{1}{2\sigma^{2}}\left[(\beta_{t+1} - G_{t+1}\beta_{t})^{\T}W_{t+1}^{-1}(\beta_{t+1} - G_{t+1}\beta_{t})\right. \right.\\
 &\left. \left.+ (\beta_{t} - m_{t})^{\T}C_{t}^{-1}(\beta_{t} - m_{t})\right]\right)\\
 &\propto \exp\left(-\frac{1}{2\sigma^{2}}\left[\beta_{t+1}^{\T}W_{t+1}^{-1}\beta_{t+1} - 2\beta_{t+1}^{\T}W_{t+1}^{-1}G_{t+1}\beta_{t} +\right.\right.\\
 &\left.\left.\beta_{t}^{\T}G_{t+1}^{\T}W_{t+1}^{-1}G_{t+1}\beta_{t} +\beta_{t}^{\T}C_{t}^{-1}\beta_{t} - 2m_{t}^{\T}C_{t}^{-1}\beta_{t} + m_{t}^{\T}C_{t}^{-1}m_{t}\right]\right)\\
 &\propto \exp\left(-\frac{1}{2\sigma^{2}}\left[\beta_{t}^{\T}(G_{t+1}^{\T}W_{t+1}^{-1}G_{t+1} + C_{t}^{-1})\beta_{t}\right.\right.\\
 &\left.\left. - 2(C_{t}^{-1}m_{t} + G_{t+1}^{\T}W_{t+1}^{-1}\beta_{t+1})^{\T}\beta_{t}\right]\right)\\
 \beta_{t}\vert\beta_{t+1},\sigma^{2},D_{T} &\sim N\left((G_{t+1}^{\T}W_{t+1}^{-1}G_{t+1} + C_{t}^{-1})^{-1}(C_{t}^{-1}m_{t} + G_{t+1}^{\T}W_{t+1}^{-1}\beta_{t+1}),\right.\\
 &\left.\sigma^{-2}(G_{t+1}^{\T}W_{t+1}^{-1}G_{t+1} + C_{t}^{-1})^{-1}\right)\\
 &\sim N\left(m_{t} - C_{t}G_{t+1}^{\T}(W_{t+1} + G_{t+1}C_{t}G_{t+1}^{\T})^{-1}G_{t+1}m_{t} +\right.\\
 &\left.C_{t}G_{t+1}^{\T}W_{t+1}^{-1}\beta_{t+1}\right.\\
 &\left.- C_{t}G_{t+1}^{\T}(W_{t+1} + G_{t+1}C_{t}G_{t+1}^{\T})^{-1}G_{t+1}C_{t}G_{t+1}^{\T}W_{t+1}^{-1}\beta_{t+1},\right.\\
 &\left.C_{t} - C_{t}G_{t+1}^{\T}(W_{t+1} + G_{t+1}C_{t}G_{t+1}^{\T})^{-1}G_{t+1}C_{t}\right)\\
 &\sim N\left(m_{t} - C_{t}G_{t+1}^{\T}R_{t+1}^{-1}G_{t+1}m_{t} + C_{t}G_{t+1}^{\T}W_{t+1}^{-1}\beta_{t+1}\right.\\
 &\left. - C_{t}G_{t+1}^{\T}R_{t+1}^{-1}G_{t+1}C_{t}G_{t+1}^{\T}W_{t+1}^{-1}\beta_{t+1},\right.\\
 &\left.C_{t} - C_{t}G_{t+1}^{\T}R_{t+1}^{-1}G_{t+1}C_{t}\right)\\
\end{split}
 (\#eq:backsample1)
\end{equation*}

Notice that
\begin{equation*}
\begin{split}
C_{t}G_{t+1}^{\T}R_{t+1}^{-1}G_{t+1}C_{t}G_{t+1}^{\T}W_{t+1}^{-1}\beta_{t+1} &= C_{t}G_{t+1}^{\T}R_{t+1}^{-1}(R_{t+1} - W_{t+1})W_{t+1}^{-1}\beta_{t+1}\\
 &= C_{t}G_{t+1}^{\T}W_{t+1}^{-1}\beta_{t+1} - C_{t}G_{t+1}^{\T}R_{t+1}^{-1}\beta_{t+1}
\end{split}
 (\#eq:Rtbreakdown)
\end{equation*}

Hence,
\begin{equation*}
\begin{split}
\beta_{t}\vert\beta_{t+1},\sigma^{2},D_{T} &\sim N\left(m_{t} - C_{t}G_{t+1}^{\T}R_{t+1}^{-1}G_{t+1}m_{t} + C_{t}G_{t+1}^{\T}W_{t+1}^{-1}\beta_{t+1}\right.\\
 &\left. - C_{t}G_{t+1}^{\T}W_{t+1}^{-1}\beta_{t+1} + C_{t}G_{t+1}^{\T}R_{t+1}^{-1}\beta_{t+1},\right.\\
 &\left.C_{t} - C_{t}G_{t+1}^{\T}R_{t+1}^{-1}G_{t+1}C_{t}\right)\\
 &\sim N(m_{t} + C_{t}G_{t+1}^{\T}R_{t+1}^{-1}(\beta_{t+1} - m_{t+1}^{*}), C_{t} - C_{t}G_{t+1}^{\T}R_{t+1}^{-1}G_{t+1}C_{t})
\end{split}
 (\#eq:backsample2)
\end{equation*}

## Sample Code

This section shows example implementations of the FFBS algorithm. Since the code can take up a lot of space in this chapter without contributing much to the discussion, code is shown only as relevant to the discussion; the messier segments of the code and the setup are largely hidden behind buttons to avoid bogging down discussion of the implementation.

The following is a small example on the built-in `r "airquality"` dataset:

```{r}
head(airquality)
```

The airquality data has 153 recorded data points from May 1 to Sept. 30 1973. We will fit a DLM for the average air quality for half of each month.

Prior to doing so, we notice that there are some missing values in the airquality data. The details are discussed in the hidden segment below:

<details>
  <summary>Click to show or hide details</summary>
  
To keep things simple, we remove the rows with missing values so that we can focus on working with complete data. (This approach is not recommended in practice.)

```{r}
airquality.complete <- airquality[complete.cases(airquality),]
```

</div>

<style>
button#toggle-button7 {
  background-color: lightgray;
  color: black;
  border-radius: 5px;
  border: none;
  padding: 5px 10px;
  font-size: 16px;
}

button#toggle-button7:hover {
  background-color: gray;
  color: white;
}
</style>

<script>
function toggleDisplay7(id) {
  var element = document.getElementById(id);
  var button = document.getElementById('toggle-button7');
  if (element.style.display === 'block') {
    element.style.display = 'none';
    button.innerHTML = 'Show details';
  } else {
    element.style.display = 'block';
    button.innerHTML = 'Hide details';
  }
}
</script>

Next we display an implementation of the FFBS in R:

<details>
  <summary>Click to show or hide details</summary>

The following contains preparatory code for rendering (and in some ways, understanding) the FFBS:

```{r}
# randomly generates a normal-inverse gamma random variable pair.
#   The inverse gamma v is sampled first from a gamma(a,b) distribution,
#   where a is the shape and b is the scale.
#   Then the normal m is sampled from N(mu, v * V).
# Returns: a list with the sampled normal and inverse gamma variable pair.

library("mvtnorm")
library("testit")

normal.inversegamma <- function(mu, V, a, b){
  assert("We need an inverse gamma with finite mean and variance. a > 2 is needed.", a > 2) 
  v <- 1/rgamma(1, shape = a, scale = b)
  m <- rmvnorm(1, mu, v * V)
  return(list(m = m, v = v))
}

library("matrixcalc")

# checks whether the matrix C is postive definite symmetric.
check.pds <- function(C, tol = 10^-9) {
  if (norm(C - t(C), type="F") < tol) {
	  C <- (C + t(C))/2
          if (!is.positive.definite(C)) {
		  cat("Warning: Matrix is not positive definite. Listing eigenvalues:", eigen(C)$values, "\n")
	  }
	  return(C)
  } else {
	  throw("Matrix symmetry is outside of tolerance: ",tol)
  }
}
```

The following functions support the operations of the DLM:

```{r}
# fills in a matrix with time-varying values to make it amenable to time-
#   varying DLM computation.
# returns: the filled matrix using values stored in X at a designated time-
#   coordinate

vec2mat <- function(v, to.row.vec = FALSE) {
  if (to.row.vec) {
    M <- matrix(v, nrow = 1, ncol = length(v))
  } else {
    M <- matrix(v, nrow = length(v), ncol = 1)
  }
  return(M)
}

timefill <- function(templateMat, prevmat, X, time){
	m <- ncol(templateMat)
	n <- nrow(templateMat)
	outmat <- vec2mat(prevmat, TRUE)

	# record nonzero coordinates in templateMat
	arr.inds <- which(templateMat!=0, arr.ind=TRUE)

	#for the set of nonzero coordinates, copy the value at that coordinate
	#  for that time slice at X to the outmat
	for (ij in 1:nrow(arr.inds)) {
		i <- arr.inds[ij,1]
		j <- arr.inds[ij,2]
		outmat[i,j] <- X[time, templateMat[i,j]]
	}
	return(outmat)
}

# timefill all relevant parameters FF, GG, V, and W for the DLM
get.time.varying.params <- function(dlm.mod, time) {
	is.FFt <- !is.null(dlm.mod$JFF)
	is.GGt <- !is.null(dlm.mod$JGG)
	is.Vt <- !is.null(dlm.mod$JV)
	is.Wt <- !is.null(dlm.mod$JW)
	FF <- dlm.mod$FF
	GG <- dlm.mod$GG
	V <- dlm.mod$V
	W <- dlm.mod$W
	if (is.FFt) {
		FF <- timefill(dlm.mod$JFF, dlm.mod$FF, dlm.mod$X, time)
	}
	if (is.GGt) {
		GG <- timefill(dlm.mod$JGG, dlm.mod$GG, dlm.mod$X, time)
	}
	if (is.Vt) {
		V <- timefill(dlm.mod$JV, dlm.mod$V, dlm.mod$X, time)
	}
	if (is.Wt) {
		W <- timefill(dlm.mod$JW, dlm.mod$W, dlm.mod$X, time)
	}
	return(list(FF = FF, GG = GG, V = V, W = W))
}
```

</div>

<style>
button#toggle-button7 {
  background-color: lightgray;
  color: black;
  border-radius: 5px;
  border: none;
  padding: 5px 10px;
  font-size: 16px;
}

button#toggle-button7:hover {
  background-color: gray;
  color: white;
}
</style>

<script>
function toggleDisplay7(id) {
  var element = document.getElementById(id);
  var button = document.getElementById('toggle-button7');
  if (element.style.display === 'block') {
    element.style.display = 'none';
    button.innerHTML = 'Show details';
  } else {
    element.style.display = 'block';
    button.innerHTML = 'Hide details';
  }
}
</script>

The following code generates the parameters via forward filter:

```{r}
FF.params.1step <- function(y, FF, GG, m, C, W, V, a, b, n, scale.random=TRUE) {
	R <- GG %*% C %*% t(GG) + W
	mstar <- GG %*% m
	Q <- FF %*% R %*% t(FF) + V
	rownames(Q) <- NULL
	colnames(Q) <- NULL
	f <- FF %*% mstar

	lQt <- chol(Q)
	lQinv_e <- backsolve(lQt, y - f, transpose=TRUE)
	anew <- a + n/2
	bnew <- b + 1/2 * norm(lQinv_e, "2")^2

	lQinvFFR <- backsolve(lQt, FF %*% R, transpose = TRUE)

	mnew <- mstar + t(lQinvFFR) %*% lQinv_e
	#	  R %*% t(FF) %*% Qinv_e
	Cnew <- R - crossprod(lQinvFFR)
	Cnew <- check.pds(Cnew)

	return(list(mstar = mstar, lRt = chol(R), lQt = lQt, f = f, a = anew, b = bnew,
		    m = mnew, C = Cnew))
}


# the full forward filter step over all time. 
#   dlm.mod is a list of parameters needed to compute the DLM package,
#       with FF and GG refering to the F_t and G_t matrices in equation 4.1, etc.
#       V and W referring to V_t and W_t respectively, and JFF, JGG, JV, and JW
#       referring to the set of entries in their respective matrices to change 
#       as the next time iteration progresses, with X[t,k] replacing
#       the entry in FF, GG, V, or W with the JFF, JGG, JV, or JW entry 
#       numbered by k respectively at time t.
#       Note here that for simplicity, we assume n_t is constant for all t.
#   scale.random determines if the model uses a random scale factor phi in the
#     shared variance case. If false, sets this scale factor to 1 for each case.
#   gibbs.df determines whether to use the Gibbs sampler implementation for the time-varying
#     discount factor for the variance. If not, the variance will be assumed to be the same
#     scale variance across all time.
# returns: full list of parameters

FF <- function(y, dlm.mod, a0, b0, scale.random = TRUE){
	#NOTE: y should be a matrix with nrow being N and ncol being n
	n = ncol(y)
	N = nrow(y)
	p = length(dlm.mod$m0)
	if (is.null(dlm.mod$GG)) {
		dlm.mod$GG <- diag(1, p, p)
	}

	# parameter lists
	m_list <- matrix(rep(0, (N+1) * p), nrow = N+1, ncol = p)
	C_list <- matrix(rep(0, (N+1) * p * p), nrow = N+1, ncol = p*p)
	a_list <- rep(a0, N+1)
	b_list <- rep(b0, N+1)
	sigma2_list <- rep(0, N+1)
	beta_list <- matrix(rep(0, (N+1) * p), nrow = N+1, ncol = p)
	lRt_list <- matrix(rep(0, N * p * p), nrow = N, ncol = p*p)
	lQt_list <- matrix(rep(0, N * n * n), nrow = N, ncol = n*n)
	f_list <- matrix(rep(0, N * n), nrow = N, ncol = n)

	m_list[1,] <- dlm.mod$m0
	C_list[1,] <- c(dlm.mod$C0)
	a_list[1] <- a0
	b_list[1] <- b0

	if (scale.random) {
		sigma2_list[1] <- 1/rgamma(1, a0, b0)
		beta_list[1,] <- rmvnorm(1, dlm.mod$m0, sigma2_list[1] * dlm.mod$C0)
	} else {
		beta_list[1,] <- rmvnorm(1, dlm.mod$m0, dlm.mod$C0)
		sigma2_list <- rep(1, N+1)
	}

	for (i in 1:N) {
		# preprocess time-variant FF and GG
		time.param.list <- get.time.varying.params(dlm.mod, i)
		C <- matrix(C_list[i,], p, p)
		FF.param.list <- FF.params.1step(y[i,], time.param.list$FF, time.param.list$GG,
					  m_list[i,], C, time.param.list$W, time.param.list$V,
					  a_list[i], b_list[i], n, scale.random)
		m_list[i+1,] <- FF.param.list$m
		C_list[i+1,] <- c(FF.param.list$C)
		a_list[i+1] <- FF.param.list$a
		b_list[i+1] <- FF.param.list$b
		lRt_list[i,] <- c(FF.param.list$lRt)
		lQt_list[i,] <- c(FF.param.list$lQt)
		f_list[i,] <- FF.param.list$f

		if (scale.random) {
			sigma2_list[i+1] <- 1/rgamma(1, FF.param.list$a, FF.param.list$b)
		}

		beta_list[i+1,] <- rmvnorm(1, FF.param.list$m, sigma2_list[i+1] * FF.param.list$C)
	}

	return(list(m = m_list, C = C_list, a = a_list, b = b_list,
		    lRt = lRt_list, lQt = lQt_list, f = f_list,
		    beta = beta_list, sigma2 = sigma2_list))
}
```

The following code encompasses backwards sampling:

```{r}
# a single step of the backwards sampling. This computes beta_t | beta_{t+1}, D_T.
#   from the forward filter case
BS.params.1step <- function(beta, m, G, C, lRt){
	hnew <- beta - G %*% m
	hnew <- backsolve(lRt, hnew, transpose = TRUE)
	hnew <- backsolve(lRt, hnew)
	hnew <- t(G) %*% hnew
	hnew <- C %*% hnew
	hnew <- m + hnew

	Hnew <- G %*% C
	Hnew <- backsolve(lRt, Hnew, transpose = TRUE)
	Hnew <- crossprod(Hnew)
	Hnew <- C - Hnew
	Hnew <- check.pds(Hnew)
	return(list(beta = beta, h = hnew, H = Hnew))
}

# the full backwards sampling algorithm for smoothing the parameters beta.
#   To get the nonrandom constant variance case,set sigma2.T = 1, or
#   alternatively, set scale.random = FALSE.
# returns: the full list of backwards-sampled beta

BS <- function(dlm.mod, m_list, C_list, lRt_list, sigma2.T, scale.random = TRUE){
	N <- nrow(m_list) - 1
	p <- ncol(m_list)

	if (!scale.random) {
		sigma2.T = 1
	}

	beta_bs_list <- matrix(rep(0, (N + 1) * p), nrow = N+1, ncol = p)
	C.T <- matrix(C_list[N+1,], p, p)
	if (scale.random) {
		beta_bs_list[N+1,] <- rmvnorm(1, m_list[N+1,], sigma2.T * C.T)
	} else {
		beta_bs_list[N+1,] <- rmvnorm(1, m_list[N+1,], C.T)
	}
	h_list <- matrix(rep(0, (N+1) * p), nrow = N+1, ncol = p)
	H_list <- matrix(rep(0, (N+1) * p * p), nrow = N+1, ncol = p * p)
	h_list[N+1,] <- m_list[N+1,]
	H_list[N+1,] <- C_list[N+1,]

	for (i in N:1){
		m <- m_list[i,]  #NOTE: m and C go from 0 to N.
		C <- matrix(C_list[i,],p,p) 
		lRt <- matrix(lRt_list[i,],p,p) # R and G go from 1 to N.
			
		time.param.list <- get.time.varying.params(dlm.mod, i)
#		mstar <- time.param.list$GG %*% m_list[i,] 
#		H <- matrix(H_list[i+1,],p,p)
#	       	bs.results.1step <- BS.1step(h_list[i+1,], S, m_list[i,], time.param.list$GG,
#					     C, lRt, sigma2.T)
		bs.results.1step <- BS.params.1step(beta_bs_list[i+1,], m, time.param.list$GG, C, lRt)
		beta_bs_list[i,] <- rmvnorm(1, bs.results.1step$h, sigma2.T * bs.results.1step$H)
		h_list[i,] <- bs.results.1step$h
		H_list[i,] <- bs.results.1step$H
	}

	return(list(beta = beta_bs_list, h = h_list, H = H_list))
}
```


We want to regress Ozone level with Solar radiation, Wind, and temperature for each day. (Note that for this case that $n_{t} = 1$ for all $t$). We begin by writing our data into the appropriate structure for our code:

<!-- TODO: transform the data into the dlm.mod form and throw it into the FFBS code. -->
```{r}
library("dplyr")

airquality.complete <- airquality.complete %>% arrange(Month,Day)

airquality.complete$t <- seq(1,nrow(airquality.complete))
airquality.complete$date <- paste(airquality.complete$Month, 
                                  airquality.complete$Day,
                                  "1973", sep="/")

y <- as.matrix(c(airquality.complete$Ozone), nrow = N, ncol = 1)
p <- 3
n <- 1
N <- nrow(airquality.complete)

X <- matrix(rep(0, N * n * p), nrow = N, ncol = n * p)

for (t in seq(1, N)) {
  X[t,]<- c(as.matrix(airquality.complete[t, c("Solar.R", "Wind", "Temp")]))
}

JFF <- matrix(seq(1, n * p), nrow = n, ncol = p)
F1 <- c(as.matrix(airquality.complete[1, c("Solar.R", "Wind", "Temp")]))

m0 <- rep(0,p)
C0 <- diag(p)

dlm.mod <- list(m0 = m0,
                C0 = C0,
                FF = F1,
                GG = diag(p),
                V = 1,
                W = diag(p),
                JFF = JFF,
                X = X)
```


We can now run the DLM on our data:

```{r}
a0 <- 3
b0 <- 1
ff.results <- FF(y, dlm.mod, a0, b0, scale.random = TRUE)

sigma2.T <- ff.results$sigma2[N+1]
cat("(sigma2 | D_T):", sigma2.T)
```

In particular, we are interested in the value of $\sigma^{2}\vert D_{T}$, because this will be the scale variance value we will use to sample our parameter estimates at the backwards sampling step:

```{r}
bs.results <- BS(dlm.mod, ff.results$m, ff.results$C, ff.results$lRt, sigma2.T, scale.random = TRUE)
```

Do some postprocessing to prepare for plotting the parameter estimates for Solar R, Wind, and Temperature:

```{r}
betas.bs <- as.data.frame(bs.results$beta)
colnames(betas.bs) <- c("Solar.R", "Wind", "Temp")
betas.bs$t <- seq(0,N)
betas.bs <- merge(betas.bs, airquality.complete[,c("t","date")])
betas.bs$date <- as.Date(betas.bs$date, tryFormats=c("%m/%d/%Y"))
```

The estimates of $\beta_{t}$ are plotted below: 

```{r}
library("ggplot2")
w <- 7
h <- 5

p1 <- ggplot(data = betas.bs, aes(x = date)) + geom_line(aes(y = Solar.R))
p2 <- ggplot(data = betas.bs, aes(x = date)) + geom_line(aes(y = Wind))
p3 <- ggplot(data = betas.bs, aes(x = date)) + geom_line(aes(y = Temp))

library("gridExtra")

grid.arrange(p1, p2, p3)
```





